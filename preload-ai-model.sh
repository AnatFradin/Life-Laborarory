#!/bin/bash

# Preload AI model into Ollama memory for faster responses
# Run this before using the rephrasing feature

MODEL="qwen3:8b"

echo "ğŸ¤– Preloading model: $MODEL"
echo "ğŸ“ Sending warmup request..."

curl -s -X POST http://localhost:11434/api/generate \
  -d "{
    \"model\": \"$MODEL\",
    \"prompt\": \"Hello\",
    \"stream\": false
  }" > /dev/null

echo "âœ… Model loaded and ready!"
echo "ğŸš€ You can now use the Rephrase feature with faster responses"
